folder: D:\Documents\summer_project\audioMNIST
data_folder: !ref <folder>
save_folder: !ref <folder>
split_ratio: [8, 1, 1]
split_base: id

output_folder: !ref <folder>/output
output_embedding_folder: !ref <folder>/output/embeddings2
train_log: !ref <output_folder>/encoder_decoder_train_log.txt
train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: !ref <train_log>

data_csv: !ref <save_folder>/data.csv
train_csv: !ref <save_folder>/train.csv
val_csv: !ref <save_folder>/val.csv
test_csv: !ref <save_folder>/test.csv

number_of_epochs: 600
batch_size: 400
lr_start: 0.001
lr_final: 0.00001
n_classes: 10
device: cuda

dataloader_options:
  batch_size: !ref <batch_size>

norm: !new:speechbrain.processing.features.InputNormalization
  norm_type: sentence
  mean_norm: False
  std_norm: False

encoder: !new:model.Encoder
  input_channel: 1
  output_channels_list: [16, 8, 4]

decoder: !new:model.Decoder
  input_channel: 4
  output_channels_list: [8, 16, 1]

modules:
  norm: !ref <norm>
  encoder: !ref <encoder>
  decoder: !ref <decoder>

opt_class: !name:torch.optim.Adam
  lr: !ref <lr_start>

error_stats: !name:speechbrain.utils.metric_stats.MetricStats
  metric: !name:speechbrain.nnet.losses.mse_loss
    reduction: batch

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: !ref <number_of_epochs>


lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler
  initial_value: !ref <lr_start>
  final_value: !ref <lr_final>
  epoch_count: !ref <number_of_epochs>

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <folder>
  recoverables:
    encoder: !ref <encoder>
    decoder: !ref <decoder>
    normalizer: !ref <norm>
    counter: !ref <epoch_counter>
